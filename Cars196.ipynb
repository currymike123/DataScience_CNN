{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (3.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (20.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (4.28.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /usr/local/lib/python3.7/site-packages (from matplotlib) (6.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib) (59.3.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "2.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Couldn't call 'get_role' to get Role ARN from role name AmazonSageMaker-ExecutionRole-20211105T103191 to get Role path.\n",
      "WARNING:sagemaker:Assuming role was created in SageMaker AWS console, as the name contains `AmazonSageMaker-ExecutionRole`. Defaulting to Role ARN with service-role in path. If this Role ARN is incorrect, please add IAM read permissions to your role or supply the Role Arn directly.\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "import os, warnings\n",
    "\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# !pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "print(tf.__version__)\n",
    "\n",
    "#Horovod for distributed training \n",
    "import horovod.tensorflow.keras as hvd\n",
    "\n",
    "#Sagemaker for running on AWS\n",
    "import sagemaker\n",
    "from sagemaker.utils import sagemaker_timestamp\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "default_s3_bucket = sagemaker_session.default_bucket()\n",
    "sagemaker_iam_role = get_execution_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Intialize Horovod \n",
    "# hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pick the master GPU\n",
    "# # Pin GPU to be used to process local rank (one GPU per process)\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "# if gpus:\n",
    "#     tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available GPU's for Horovod\n",
    "# print(hvd.local_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and process annotations\n",
    "cars_meta = scipy.io.loadmat('./Annos/cars_meta.mat')\n",
    "class_names = cars_meta['class_names']  # shape=(1, 196)\n",
    "class_names = np.transpose(class_names)\n",
    "\n",
    "train_annos = scipy.io.loadmat('./Annos/cars_train_annos.mat')\n",
    "train_annos = train_annos['annotations']\n",
    "train_annos = np.transpose(train_annos)\n",
    "\n",
    "test_annos = scipy.io.loadmat('./Annos/cars_test_annos_withlabels.mat')\n",
    "test_annos = test_annos['annotations']\n",
    "test_annos = np.transpose(test_annos)\n",
    "\n",
    "def format_annotations(data):\n",
    "\n",
    "    annos = []\n",
    " \n",
    "    for annotation in data:\n",
    "        bbox_x1 = annotation[0][0][0][0]\n",
    "        bbox_y1 = annotation[0][1][0][0]\n",
    "        bbox_x2 = annotation[0][2][0][0]\n",
    "        bbox_y2 = annotation[0][3][0][0]\n",
    "        class_id = annotation[0][4][0][0]\n",
    "        fname = annotation[0][5][0]\n",
    "        annos.append([fname,[bbox_x1, bbox_y1, bbox_x2, bbox_y2],class_id])\n",
    "    \n",
    "    return(annos)\n",
    "\n",
    "train_annotations = format_annotations(train_annos)\n",
    "test_annotations = format_annotations(test_annos)\n",
    "\n",
    "#get annotations train_annotations[0][2]. First index is the number of images.  Second index is [0] for frame name. [1] for box. [2] for class_id\n",
    "\n",
    "#save labels as list\n",
    "def labels_list(data):\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for label in data:\n",
    "        labels.append(label[2])\n",
    "\n",
    "    return(labels)\n",
    "\n",
    "def fnames_list(data):\n",
    "\n",
    "    fnames = []\n",
    "\n",
    "    for fname in data:\n",
    "        fnames.append(fname[0])\n",
    "    \n",
    "    return(fnames)\n",
    "\n",
    "train_labels = labels_list(train_annotations)\n",
    "test_labels = labels_list(test_annotations)\n",
    "\n",
    "\n",
    "train_fnames = fnames_list(train_annotations)\n",
    "test_fnames = fnames_list(test_annotations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['08144.jpg', [20, 240, 862, 677], 17]\n",
      "[39, 116, 569, 375]\n",
      "39 116 569 375\n",
      "['00001.jpg', [30, 52, 246, 147], 181]\n",
      "[30, 52, 246, 147]\n",
      "30 52 246 147\n"
     ]
    }
   ],
   "source": [
    "print(train_annotations[8143])\n",
    "print(train_annotations[0][1])\n",
    "index = 0\n",
    "x1 = train_annotations[index][1][0]\n",
    "y1 = train_annotations[index][1][1]\n",
    "x2 = train_annotations[index][1][2]\n",
    "y2 = train_annotations[index][1][3]\n",
    "print(x1,y1,x2,y2)\n",
    "\n",
    "print(test_annotations[0])\n",
    "print(test_annotations[0][1])\n",
    "index = 0\n",
    "x1 = test_annotations[index][1][0]\n",
    "y1 = test_annotations[index][1][1]\n",
    "x2 = test_annotations[index][1][2]\n",
    "y2 = test_annotations[index][1][3]\n",
    "print(x1,y1,x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "13185\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "directory_train = './cars196_train/'\n",
    "directory_test = './cars196_test/'\n",
    "\n",
    "\n",
    "# Create Datasets\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((train_fnames, train_labels))\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((test_fnames, test_labels))\n",
    "\n",
    "def train_read_image(image_file, label):\n",
    "    image = tf.io.read_file(directory_train + image_file)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return image, label\n",
    "\n",
    "def test_read_image(image_file, label):\n",
    "    image = tf.io.read_file(directory_test + image_file)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def augment(image_file,label):\n",
    "    image_size = [256,256]\n",
    "    num_channels = 3\n",
    "    interpolation = 'nearest'\n",
    "    img = tf.image.resize(image_file, image_size, method=interpolation)\n",
    "    img.set_shape((image_size[0], image_size[1], num_channels))\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "\n",
    "def load_images(data):\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for image in data:\n",
    "        image = tf.io.read_file(directory_train + image)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        images.append(image)\n",
    "\n",
    "    return images\n",
    "\n",
    "# Putting it all together.  Take the training dataset which is sized and labeled.  Convert to pixel array.  Cache in memory for faster runtime.  Autotune sets up the CPU so it's fetching the next image in the list while the current image is in the CNN.  \n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = ds_train.map(train_read_image).map(augment).map(convert_to_float)\n",
    "ds_test = ds_test.map(test_read_image).map(augment).map(convert_to_float)\n",
    "\n",
    "\n",
    "# Add the datasets together so I can put more into the train \n",
    "ds_train = ds_train.concatenate(ds_test)\n",
    "ds_test = ds_train.take(3000)\n",
    "ds_train = ds_train.skip(3000) \n",
    "print(len(ds_test))\n",
    "print(len(ds_train))\n",
    "ds_train = ds_train.batch(64).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "ds_test = ds_test.batch(64).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Pretrained Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 0\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# InceptionV3 pretrained base.\n",
    "\n",
    "# pretrained_base = tf.keras.applications.inception_v3.InceptionV3(\n",
    "#     include_top=False, weights='imagenet', input_tensor=None,\n",
    "#     input_shape=[256,256,3], pooling=None, classes=1000,\n",
    "#     classifier_activation='softmax'\n",
    "# )\n",
    "# pretrained_base.trainable = False\n",
    "\n",
    "# VGG16 pretrained base.\n",
    "pretrained_base = tf.keras.applications.vgg19.VGG19(\n",
    "    include_top=False, weights='imagenet', input_tensor=None,\n",
    "    input_shape=[256,256,3], pooling=None,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "pretrained_base.trainable = False\n",
    "\n",
    "pretrained_base.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop early if the accucary is not improving enough.\n",
    "\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# early_stopping = EarlyStopping(\n",
    "#     min_delta=0.0005, # minimium amount of change to count as an improvement\n",
    "#     patience=15, # how many epochs to wait before stopping\n",
    "#     restore_best_weights=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# data_augmentation = tf.keras.Sequential([\n",
    "#     layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "#     layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "# #     layers.experimental.preprocessing.RandomContrast(0.5),\n",
    "# #     layers.experimental.preprocessing.RandomTranslation((-0.2,0.2),(-0.2,0.2)),\n",
    "# #     layers.experimental.preprocessing.Rescaling(scale=1./255),\n",
    "# #     layers.experimental.preprocessing.RandomZoom((0,0.2)),\n",
    "    \n",
    "\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "# print(\"Number of devices: {}\".format(mirrored_strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential([\n",
    "#     pretrained_base,\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(units=512, activation='relu'),\n",
    "#     layers.Dropout(0.7),\n",
    "#     layers.Dense(units=197, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# 48% with pretrained base and without data_augmentation\n",
    "\n",
    "\n",
    "\n",
    "# with mirrored_strategy.scope():\n",
    "    \n",
    "# pretrained_base = tf.keras.applications.vgg19.VGG19(\n",
    "# include_top=False, weights='imagenet', input_tensor=None,\n",
    "# input_shape=[256,256,3], pooling=None,\n",
    "# classifier_activation='softmax'\n",
    "# )\n",
    "# pretrained_base.trainable = False\n",
    "# # Train the last convolution block in the VGG19 base\n",
    "# # pretrained_base.trainable = True\n",
    "\n",
    "# # set_trainable = False\n",
    "# # for layer in pretrained_base.layers:\n",
    "# #     if layer.name == 'block5_conv1':\n",
    "# #         set_trainable = True\n",
    "# #     if set_trainable:\n",
    "# #         layer.trainable = True\n",
    "# #     else:\n",
    "# #         layer.trainable = False\n",
    "\n",
    "# # Data Augmentation to generalize the data   \n",
    "# data_augmentation = tf.keras.Sequential([\n",
    "# layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "# layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "# layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "# #     layers.experimental.preprocessing.Rescaling(scale=1./255),\n",
    "# #     layers.experimental.preprocessing.RandomZoom((0,0.2)),\n",
    "# ])\n",
    "\n",
    "# Build Model\n",
    "# model = keras.Sequential([\n",
    "#     data_augmentation,\n",
    "#     pretrained_base,\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(units=4096, activation=\"relu\"),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.25),\n",
    "#     layers.Dense(units=2048, activation=\"relu\"),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.25),\n",
    "#     layers.Dense(units=1024, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.25),\n",
    "#     layers.Dense(units=512, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.25),\n",
    "#     layers.Dense(units=256, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.25),\n",
    "#     layers.Dense(units=197, activation=\"softmax\"),\n",
    "# ])\n",
    "\n",
    "# # Build Model\n",
    "# model = keras.Sequential([\n",
    "# #     data_augmentation,\n",
    "#     pretrained_base,\n",
    "#     layers.Flatten(),\n",
    "# #     layers.Dense(units=4096, activation=\"relu\"),\n",
    "# #     layers.BatchNormalization(),\n",
    "# #     layers.Dropout(0.3),\n",
    "#     layers.Dense(units=2048, activation=\"relu\"),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.3),\n",
    "#     layers.Dense(units=1024, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.3),\n",
    "#     layers.Dense(units=512, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.3),\n",
    "#     layers.Dense(units=256, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.3),\n",
    "#     layers.Dense(units=197, activation=\"softmax\"),\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "# Custom base  0.8051346 val_binary_accuracy\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "\n",
    "    # First Convolutional Block\n",
    "    # 32 filter layers, Kernel Size of 5 x 5. Relu activation.  Add zeroes all around so the image doesn't change size, Padding='same'.\n",
    "    \n",
    "    layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same',\n",
    "                  # give the input dimensions in the first layer\n",
    "                  # [height, width, color channels(RGB)]\n",
    "                  input_shape=[256, 256, 3]),\n",
    "    \n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
    " \n",
    "    layers.MaxPool2D(),\n",
    "    \n",
    "\n",
    "    # Third Convolutional Block\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "    \n",
    "    layers.MaxPool2D(),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    #Fourth Convolutional Block\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "    \n",
    "    layers.MaxPool2D(),\n",
    "    \n",
    "\n",
    "    #Fifth Convolutional Block\n",
    "    layers.Conv2D(filters=512, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "   \n",
    "    layers.MaxPool2D(),\n",
    "    \n",
    "    #Fifth Convolutional Block\n",
    "    layers.Conv2D(filters=1024, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "  \n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "   \n",
    "#     # Classifier Head.  Fully connected Dense layer with 6 nodes and a relu activation.  Final node for binary decision. \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=2048, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(units=1024, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(units=512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(units=256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(units=197, activation=\"softmax\"),\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "# Set the optimizer to Adam with a learning rate of 0.0001\n",
    "\n",
    "opt = tf.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = tf.optimizers.Adam(0.001 * hvd.size())\n",
    "# # Horovod: add Horovod DistributedOptimizer.\n",
    "# opt = hvd.DistributedOptimizer(opt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(hvd.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "207/207 [==============================] - 67s 325ms/step - loss: 6.0861 - accuracy: 0.0063 - val_loss: 6.8784 - val_accuracy: 0.0060\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 38s 183ms/step - loss: 5.9249 - accuracy: 0.0078 - val_loss: 7.7420 - val_accuracy: 0.0087\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 5.7348 - accuracy: 0.0096 - val_loss: 5.5852 - val_accuracy: 0.0153\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 5.6004 - accuracy: 0.0129 - val_loss: 5.2679 - val_accuracy: 0.0200\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 38s 183ms/step - loss: 5.5056 - accuracy: 0.0133 - val_loss: 5.1779 - val_accuracy: 0.0183\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 38s 183ms/step - loss: 5.3842 - accuracy: 0.0162 - val_loss: 5.5398 - val_accuracy: 0.0150\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 5.3135 - accuracy: 0.0183 - val_loss: 4.9730 - val_accuracy: 0.0297\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 5.2596 - accuracy: 0.0214 - val_loss: 5.1682 - val_accuracy: 0.0180\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 38s 183ms/step - loss: 5.1742 - accuracy: 0.0256 - val_loss: 4.8744 - val_accuracy: 0.0330\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 5.0817 - accuracy: 0.0297 - val_loss: 4.8332 - val_accuracy: 0.0350\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 5.0097 - accuracy: 0.0325 - val_loss: 4.9289 - val_accuracy: 0.0363\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 4.9202 - accuracy: 0.0343 - val_loss: 5.2838 - val_accuracy: 0.0290\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 4.8258 - accuracy: 0.0407 - val_loss: 4.8352 - val_accuracy: 0.0460\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 4.7067 - accuracy: 0.0476 - val_loss: 4.8594 - val_accuracy: 0.0410\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 4.6215 - accuracy: 0.0526 - val_loss: 4.7673 - val_accuracy: 0.0510\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 4.5374 - accuracy: 0.0578 - val_loss: 4.5917 - val_accuracy: 0.0630\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 4.4205 - accuracy: 0.0686 - val_loss: 4.7389 - val_accuracy: 0.0657\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 4.3144 - accuracy: 0.0791 - val_loss: 4.4328 - val_accuracy: 0.0780\n",
      "Epoch 19/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 4.2095 - accuracy: 0.0846 - val_loss: 4.0903 - val_accuracy: 0.1080\n",
      "Epoch 20/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 4.1189 - accuracy: 0.0976 - val_loss: 4.1329 - val_accuracy: 0.0990\n",
      "Epoch 21/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 4.0112 - accuracy: 0.1100 - val_loss: 3.9244 - val_accuracy: 0.1247\n",
      "Epoch 22/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 3.8948 - accuracy: 0.1198 - val_loss: 4.0422 - val_accuracy: 0.1113\n",
      "Epoch 23/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 3.7889 - accuracy: 0.1354 - val_loss: 3.8126 - val_accuracy: 0.1310\n",
      "Epoch 24/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 3.6950 - accuracy: 0.1497 - val_loss: 3.4937 - val_accuracy: 0.1743\n",
      "Epoch 25/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 3.5713 - accuracy: 0.1704 - val_loss: 3.8050 - val_accuracy: 0.1387\n",
      "Epoch 26/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 3.4647 - accuracy: 0.1859 - val_loss: 3.2227 - val_accuracy: 0.2153\n",
      "Epoch 27/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 3.3624 - accuracy: 0.1943 - val_loss: 3.2613 - val_accuracy: 0.2263\n",
      "Epoch 28/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 3.2274 - accuracy: 0.2155 - val_loss: 3.0701 - val_accuracy: 0.2577\n",
      "Epoch 29/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 3.1323 - accuracy: 0.2321 - val_loss: 2.9404 - val_accuracy: 0.2703\n",
      "Epoch 30/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 3.0165 - accuracy: 0.2488 - val_loss: 3.1086 - val_accuracy: 0.2377\n",
      "Epoch 31/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 2.9172 - accuracy: 0.2681 - val_loss: 2.7824 - val_accuracy: 0.3140\n",
      "Epoch 32/100\n",
      "207/207 [==============================] - 38s 183ms/step - loss: 2.7904 - accuracy: 0.2957 - val_loss: 2.6560 - val_accuracy: 0.3303\n",
      "Epoch 33/100\n",
      "207/207 [==============================] - 38s 182ms/step - loss: 2.6619 - accuracy: 0.3193 - val_loss: 2.4879 - val_accuracy: 0.3733\n",
      "Epoch 34/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 2.5669 - accuracy: 0.3442 - val_loss: 2.4791 - val_accuracy: 0.3720\n",
      "Epoch 35/100\n",
      "207/207 [==============================] - 38s 183ms/step - loss: 2.4764 - accuracy: 0.3572 - val_loss: 2.4257 - val_accuracy: 0.3870\n",
      "Epoch 36/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 2.3562 - accuracy: 0.3885 - val_loss: 2.3628 - val_accuracy: 0.4000\n",
      "Epoch 37/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 2.2738 - accuracy: 0.4033 - val_loss: 2.1736 - val_accuracy: 0.4563\n",
      "Epoch 38/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 2.1506 - accuracy: 0.4309 - val_loss: 2.2290 - val_accuracy: 0.4303\n",
      "Epoch 39/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 2.0520 - accuracy: 0.4597 - val_loss: 2.0141 - val_accuracy: 0.4827\n",
      "Epoch 40/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.9701 - accuracy: 0.4719 - val_loss: 1.9590 - val_accuracy: 0.4937\n",
      "Epoch 41/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.8974 - accuracy: 0.4992 - val_loss: 1.8316 - val_accuracy: 0.5270\n",
      "Epoch 42/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.7872 - accuracy: 0.5142 - val_loss: 1.7117 - val_accuracy: 0.5497\n",
      "Epoch 43/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.6970 - accuracy: 0.5380 - val_loss: 1.7886 - val_accuracy: 0.5240\n",
      "Epoch 44/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.6352 - accuracy: 0.5551 - val_loss: 1.7297 - val_accuracy: 0.5443\n",
      "Epoch 45/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.5556 - accuracy: 0.5710 - val_loss: 1.6999 - val_accuracy: 0.5500\n",
      "Epoch 46/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.4854 - accuracy: 0.5918 - val_loss: 1.6007 - val_accuracy: 0.5867\n",
      "Epoch 47/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.4155 - accuracy: 0.6074 - val_loss: 1.6269 - val_accuracy: 0.5643\n",
      "Epoch 48/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.3700 - accuracy: 0.6176 - val_loss: 1.5499 - val_accuracy: 0.5923\n",
      "Epoch 49/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.2977 - accuracy: 0.6410 - val_loss: 1.5187 - val_accuracy: 0.5913\n",
      "Epoch 50/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.2160 - accuracy: 0.6594 - val_loss: 1.4096 - val_accuracy: 0.6143\n",
      "Epoch 51/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.1759 - accuracy: 0.6731 - val_loss: 1.4353 - val_accuracy: 0.6167\n",
      "Epoch 52/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 1.1090 - accuracy: 0.6879 - val_loss: 1.4137 - val_accuracy: 0.6173\n",
      "Epoch 53/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 1.0713 - accuracy: 0.6984 - val_loss: 1.3821 - val_accuracy: 0.6257\n",
      "Epoch 54/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 1.0032 - accuracy: 0.7195 - val_loss: 1.3780 - val_accuracy: 0.6340\n",
      "Epoch 55/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.9572 - accuracy: 0.7317 - val_loss: 1.4048 - val_accuracy: 0.6173\n",
      "Epoch 56/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.9147 - accuracy: 0.7412 - val_loss: 1.3535 - val_accuracy: 0.6383\n",
      "Epoch 57/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.8681 - accuracy: 0.7584 - val_loss: 1.2962 - val_accuracy: 0.6520\n",
      "Epoch 58/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.8466 - accuracy: 0.7564 - val_loss: 1.3198 - val_accuracy: 0.6473\n",
      "Epoch 59/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.8047 - accuracy: 0.7700 - val_loss: 1.3765 - val_accuracy: 0.6467\n",
      "Epoch 60/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.7642 - accuracy: 0.7842 - val_loss: 1.2556 - val_accuracy: 0.6650\n",
      "Epoch 61/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.7450 - accuracy: 0.7873 - val_loss: 1.2906 - val_accuracy: 0.6627\n",
      "Epoch 62/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.7147 - accuracy: 0.7963 - val_loss: 1.2541 - val_accuracy: 0.6697\n",
      "Epoch 63/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.6885 - accuracy: 0.8042 - val_loss: 1.2445 - val_accuracy: 0.6677\n",
      "Epoch 64/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.6427 - accuracy: 0.8184 - val_loss: 1.2593 - val_accuracy: 0.6737\n",
      "Epoch 65/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.6214 - accuracy: 0.8182 - val_loss: 1.2508 - val_accuracy: 0.6733\n",
      "Epoch 66/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.5916 - accuracy: 0.8299 - val_loss: 1.2701 - val_accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.5737 - accuracy: 0.8335 - val_loss: 1.2914 - val_accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.5375 - accuracy: 0.8465 - val_loss: 1.3245 - val_accuracy: 0.6600\n",
      "Epoch 69/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.5303 - accuracy: 0.8444 - val_loss: 1.2545 - val_accuracy: 0.6757\n",
      "Epoch 70/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.5020 - accuracy: 0.8569 - val_loss: 1.2563 - val_accuracy: 0.6777\n",
      "Epoch 71/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.4755 - accuracy: 0.8620 - val_loss: 1.2492 - val_accuracy: 0.6790\n",
      "Epoch 72/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.4742 - accuracy: 0.8613 - val_loss: 1.2334 - val_accuracy: 0.6787\n",
      "Epoch 73/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.4643 - accuracy: 0.8633 - val_loss: 1.1744 - val_accuracy: 0.6950\n",
      "Epoch 74/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.4358 - accuracy: 0.8749 - val_loss: 1.2016 - val_accuracy: 0.6907\n",
      "Epoch 75/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.4183 - accuracy: 0.8815 - val_loss: 1.1804 - val_accuracy: 0.6947\n",
      "Epoch 76/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.4154 - accuracy: 0.8798 - val_loss: 1.3012 - val_accuracy: 0.6710\n",
      "Epoch 77/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.3947 - accuracy: 0.8856 - val_loss: 1.2066 - val_accuracy: 0.6877\n",
      "Epoch 78/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.3800 - accuracy: 0.8915 - val_loss: 1.2633 - val_accuracy: 0.6800\n",
      "Epoch 79/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.3855 - accuracy: 0.8875 - val_loss: 1.3256 - val_accuracy: 0.6680\n",
      "Epoch 80/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.3673 - accuracy: 0.8933 - val_loss: 1.2884 - val_accuracy: 0.6837\n",
      "Epoch 81/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.3479 - accuracy: 0.9003 - val_loss: 1.1853 - val_accuracy: 0.6977\n",
      "Epoch 82/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.3314 - accuracy: 0.9077 - val_loss: 1.2521 - val_accuracy: 0.6890\n",
      "Epoch 83/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.3221 - accuracy: 0.9071 - val_loss: 1.2270 - val_accuracy: 0.6877\n",
      "Epoch 84/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.3105 - accuracy: 0.9080 - val_loss: 1.1963 - val_accuracy: 0.6960\n",
      "Epoch 85/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.3042 - accuracy: 0.9152 - val_loss: 1.2966 - val_accuracy: 0.6747\n",
      "Epoch 86/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.3108 - accuracy: 0.9082 - val_loss: 1.4045 - val_accuracy: 0.6640\n",
      "Epoch 87/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.2929 - accuracy: 0.9132 - val_loss: 1.3625 - val_accuracy: 0.6723\n",
      "Epoch 88/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.2831 - accuracy: 0.9165 - val_loss: 1.3454 - val_accuracy: 0.6820\n",
      "Epoch 89/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.2792 - accuracy: 0.9188 - val_loss: 1.3251 - val_accuracy: 0.6887\n",
      "Epoch 90/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.2683 - accuracy: 0.9223 - val_loss: 1.2062 - val_accuracy: 0.7030\n",
      "Epoch 91/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.2687 - accuracy: 0.9220 - val_loss: 1.2714 - val_accuracy: 0.6963\n",
      "Epoch 92/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.2646 - accuracy: 0.9226 - val_loss: 1.2761 - val_accuracy: 0.7013\n",
      "Epoch 93/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 0.2564 - accuracy: 0.9245 - val_loss: 1.1949 - val_accuracy: 0.7070\n",
      "Epoch 94/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.2344 - accuracy: 0.9313 - val_loss: 1.3216 - val_accuracy: 0.6873\n",
      "Epoch 95/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.2287 - accuracy: 0.9336 - val_loss: 1.2005 - val_accuracy: 0.7140\n",
      "Epoch 96/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.2330 - accuracy: 0.9316 - val_loss: 1.1850 - val_accuracy: 0.7190\n",
      "Epoch 97/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.2382 - accuracy: 0.9310 - val_loss: 1.3565 - val_accuracy: 0.6897\n",
      "Epoch 98/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.2347 - accuracy: 0.9312 - val_loss: 1.4410 - val_accuracy: 0.6760\n",
      "Epoch 99/100\n",
      "207/207 [==============================] - 38s 185ms/step - loss: 0.2179 - accuracy: 0.9345 - val_loss: 1.4912 - val_accuracy: 0.6670\n",
      "Epoch 100/100\n",
      "207/207 [==============================] - 38s 184ms/step - loss: 0.2107 - accuracy: 0.9377 - val_loss: 1.2942 - val_accuracy: 0.7073\n"
     ]
    }
   ],
   "source": [
    "#Compile.  Use the Adam optimizer which uses stochastic gradient descent to adjust weights.  Binary_crossentropy since it's either 'car' or 'truck.\n",
    "\n",
    "# # Set the optimizer to Adam with a learning rate of 0.0001\n",
    "# opt = tf.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=opt,\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy'],\n",
    "# )\n",
    "\n",
    "# callbacks = [\n",
    "#     # Horovod: broadcast initial variable states from rank 0 to all other processes.\n",
    "#     # This is necessary to ensure consistent initialization of all workers when\n",
    "#     # training is started with random weights or restored from a checkpoint.\n",
    "#     hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n",
    "# ]\n",
    "\n",
    "# # Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\n",
    "# if hvd.rank() == 0:\n",
    "#     callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n",
    "    \n",
    "# Horovod: adjust number of epochs based on number of GPUs.\n",
    "# epochs = int(math.ceil(30 / hvd.size()))\n",
    "epochs = 100\n",
    "# batch_size = 20\n",
    "\n",
    "# Fit the Model. \n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data = ds_test,\n",
    "    epochs = epochs,\n",
    "#     callbacks=[early_stopping], \n",
    "    verbose=1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {

      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy and loss after 30 Epochs\n",
    "\n",
    "# caption = 'Base: VGG19' '\\n' 'Convd 5 trainable''\\n' 'Train: 80%''\\n''Test: 20%''\\n''Head: 4096 -> 256, Batch Normalization, Dropout: 0.25' '\\n' 'Data Aug: Flip Horizontal, Rotation 0.1, Contrast: 0.2'\n",
    "caption = 'Base: 32 -> 1024, MaxPool' '\\n' 'Train: 80%''\\n''Test: 20%''\\n''Head: 2048 -> 256, Batch Normalization, Dropout 0.4' '\\n' 'Data Aug: Flip Horizontal, Rotation 0.1' \n",
    "\n",
    "# Train/Test Accuracy Plot\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Custom_0_100')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.text(-.5,-.5, caption)\n",
    "\n",
    "# Save as PDF\n",
    "plt.savefig(\"Custom_0_100_2048_256_Norm_Dropout_accuracy.pdf\", bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Train/Test Loss Plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Custom_0_100')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.text(-.5,-3.5, caption)\n",
    "\n",
    "# Save as PDF\n",
    "plt.savefig(\"Custom_0_100_2048_256_Norm_Dropout_loss.pdf\", bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Save Model\n",
    "model.save('vgg19_30_100_2048_256_Norm_Dropout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "e47b1a34c05c1e3b83a62d7885c9d1b5ef8a0522d3be0182d0a008ec409b2b3d"
  },
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
