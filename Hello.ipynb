{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My First Visual Studio Code, Tensorflow, & Jupyter Notebook Project\n",
    "\n",
    "Code copied from https://www.kaggle.com/ryanholbrook/custom-convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and process annotations\n",
    "cars_meta = scipy.io.loadmat('./Annos/cars_meta.mat')\n",
    "class_names = cars_meta['class_names']  # shape=(1, 196)\n",
    "class_names = np.transpose(class_names)\n",
    "\n",
    "train_annos = scipy.io.loadmat('./Annos/cars_train_annos.mat')\n",
    "train_annos = train_annos['annotations']\n",
    "train_annos = np.transpose(train_annos)\n",
    "\n",
    "test_annos = scipy.io.loadmat('./Annos/cars_test_annos_withlabels.mat')\n",
    "test_annos = test_annos['annotations']\n",
    "test_annos = np.transpose(test_annos)\n",
    "\n",
    "def format_annotations(data):\n",
    "\n",
    "    annos = []\n",
    " \n",
    "    for annotation in data:\n",
    "        bbox_x1 = annotation[0][0][0][0]\n",
    "        bbox_y1 = annotation[0][1][0][0]\n",
    "        bbox_x2 = annotation[0][2][0][0]\n",
    "        bbox_y2 = annotation[0][3][0][0]\n",
    "        class_id = annotation[0][4][0][0]\n",
    "        fname = annotation[0][5][0]\n",
    "        annos.append([fname,[bbox_x1, bbox_y1, bbox_x2, bbox_y2],class_id])\n",
    "    \n",
    "    return(annos)\n",
    "\n",
    "train_annotations = format_annotations(train_annos)\n",
    "test_annotations = format_annotations(test_annos)\n",
    "\n",
    "#get annotations train_annotations[0][2]. First index is the number of images.  Second index is [0] for frame name. [1] for box. [2] for class_id\n",
    "\n",
    "#save labels as list\n",
    "def labels_list(data):\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for label in data:\n",
    "        labels.append(label[2])\n",
    "\n",
    "    return(labels)\n",
    "\n",
    "def fnames_list(data):\n",
    "\n",
    "    fnames = []\n",
    "\n",
    "    for fname in data:\n",
    "        fnames.append(fname[0])\n",
    "    \n",
    "    return(fnames)\n",
    "\n",
    "train_labels = labels_list(train_annotations)\n",
    "test_labels = labels_list(test_annotations)\n",
    "\n",
    "\n",
    "train_fnames = fnames_list(train_annotations)\n",
    "test_fnames = fnames_list(test_annotations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['08144.jpg', [20, 240, 862, 677], 17]\n",
      "[39, 116, 569, 375]\n",
      "39 116 569 375\n",
      "['00001.jpg', [30, 52, 246, 147], 181]\n",
      "[30, 52, 246, 147]\n",
      "30 52 246 147\n"
     ]
    }
   ],
   "source": [
    "print(train_annotations[8143])\n",
    "print(train_annotations[0][1])\n",
    "index = 0\n",
    "x1 = train_annotations[index][1][0]\n",
    "y1 = train_annotations[index][1][1]\n",
    "x2 = train_annotations[index][1][2]\n",
    "y2 = train_annotations[index][1][3]\n",
    "print(x1,y1,x2,y2)\n",
    "\n",
    "print(test_annotations[0])\n",
    "print(test_annotations[0][1])\n",
    "index = 0\n",
    "x1 = test_annotations[index][1][0]\n",
    "y1 = test_annotations[index][1][1]\n",
    "x2 = test_annotations[index][1][2]\n",
    "y2 = test_annotations[index][1][3]\n",
    "print(x1,y1,x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**Crop to bounding box.  Only run with full resolution images.**\n",
    "\n",
    "# import PIL\n",
    "# import os\n",
    "# import os.path\n",
    "# from PIL import Image\n",
    "\n",
    "# f = r'./cars196_train'\n",
    "# #f = r'./cars196_test'\n",
    "# index = 0\n",
    "\n",
    "# for file in sorted(os.listdir(f)):\n",
    "\n",
    "#     # x1 = test_annotations[index][1][0]\n",
    "#     # y1 = test_annotations[index][1][1] \n",
    "#     # x2 = test_annotations[index][1][2]\n",
    "#     # y2 = test_annotations[index][1][3]\n",
    "\n",
    "#     x1 = train_annotations[index][1][0]\n",
    "#     y1 = train_annotations[index][1][1] \n",
    "#     x2 = train_annotations[index][1][2]\n",
    "#     y2 = train_annotations[index][1][3]\n",
    "\n",
    "    \n",
    "    \n",
    "#     f_img = f+\"/\"+file\n",
    "#     print(f_img)\n",
    "#     if(file != '.DS_Store'):\n",
    "#         img = Image.open(f_img)\n",
    "#         img = img.crop((x1,y1,x2,y2))\n",
    "#         img.save(f_img)\n",
    "#         index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 20:14:16.408595: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Reproducability\n",
    "# Setup the random seed so training data is feed in the same each run.\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "# The plotting layout presets.\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "\n",
    "directory_train = './cars196_train/'\n",
    "directory_test = './cars196_test/'\n",
    "\n",
    "\n",
    "# Create Datasets\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((train_fnames, train_labels))\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((test_fnames, test_labels))\n",
    "\n",
    "def train_read_image(image_file, label):\n",
    "    image = tf.io.read_file(directory_train + image_file)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return image, label\n",
    "\n",
    "def test_read_image(image_file, label):\n",
    "    image = tf.io.read_file(directory_test + image_file)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def augment(image_file,label):\n",
    "    image_size = [256,256]\n",
    "    num_channels = 3\n",
    "    interpolation = 'nearest'\n",
    "    img = tf.image.resize(image_file, image_size, method=interpolation)\n",
    "    img.set_shape((image_size[0], image_size[1], num_channels))\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "\n",
    "def load_images(data):\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for image in data:\n",
    "        image = tf.io.read_file(directory_train + image)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        images.append(image)\n",
    "\n",
    "    return images\n",
    "\n",
    "# Putting it all together.  Take the training dataset which is sized and labeled.  Convert to pixel array.  Cache in memory for faster runtime.  Autotune sets up the CPU so it's fetching the next image in the list while the current image is in the CNN.  \n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = ds_train.map(train_read_image).map(augment).map(convert_to_float).batch(64).shuffle(100).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "ds_test = ds_test.map(test_read_image).map(augment).map(convert_to_float).batch(64).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reproducability\n",
    "# Setup the random seed so training data is feed in the same each run.\n",
    "# def set_seed(seed=31415):\n",
    "#     np.random.seed(seed)\n",
    "#     tf.random.set_seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "# set_seed()\n",
    "\n",
    "# # Set Matplotlib defaults\n",
    "# # The plotting layout presets.\n",
    "# plt.rc('figure', autolayout=True)\n",
    "# plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "#        titleweight='bold', titlesize=18, titlepad=10)\n",
    "# plt.rc('image', cmap='magma')\n",
    "\n",
    "\n",
    "# #Create a tensorflow datasta (tf.data.Dataset).  Matches the images with the categorical label.  All the images are 128x128 and if they need to be resized use nearsest neighbor interpolation.    Shuffle the training set.  Do not shuffle the validation set.  It doesn't matter the order of the validation no need to shuffle. \n",
    "# ds_train_ = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     directory='./cars196_train',\n",
    "#     labels=train_labels,\n",
    "#     #Changed from binary to categorical_crossentropy because of the expanded labels.\n",
    "#     label_mode='int',\n",
    "#     image_size=[128, 128],\n",
    "#     interpolation='nearest',\n",
    "#     batch_size=64,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "# ds_valid_ = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     directory='/cars196_test',\n",
    "#     labels=test_labels,\n",
    "#     #Changed from binary to categorical_crossentropy because of the expanded labels.\n",
    "#     label_mode='int',\n",
    "#     image_size=[128, 128],\n",
    "#     interpolation='nearest',\n",
    "#     batch_size=64,\n",
    "#     shuffle=False,\n",
    "# )\n",
    "\n",
    "# # Data Pipeline\n",
    "# # Process the images into pixel arrays so matrix operations can be preformed on them.  \n",
    "# def convert_to_float(image, label):\n",
    "#     image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "#     return image, label\n",
    "\n",
    "# # Putting it all together.  Take the training dataset which is sized and labeled.  Convert to pixel array.  Cache in memory for faster runtime.  Autotune sets up the CPU so it's fetching the next image in the list while the current image is in the CNN.  \n",
    "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# ds_train = (\n",
    "#     ds_train_\n",
    "#     .map(convert_to_float)\n",
    "#     .cache()\n",
    "#     .prefetch(buffer_size=AUTOTUNE)\n",
    "# )\n",
    "# ds_valid = (\n",
    "#     ds_valid_\n",
    "#     .map(convert_to_float)\n",
    "#     .cache()\n",
    "#     .prefetch(buffer_size=AUTOTUNE)\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Pretrained Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#InceptionV3 pretrained base for baseline.\n",
    "\n",
    "pretrained_base = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=False, weights='imagenet', input_tensor=None,\n",
    "    input_shape=[256,256,3], pooling=max, classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "pretrained_base.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop early if the accucary is not improving enough.\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.0005, # minimium amount of change to count as an improvement\n",
    "    patience=15, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 6, 6, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2048)              150996992 \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 197)               101061    \n",
      "=================================================================\n",
      "Total params: 175,538,149\n",
      "Trainable params: 153,728,197\n",
      "Non-trainable params: 21,809,952\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pretrained base model\n",
    "\n",
    "model = keras.Sequential([\n",
    "    pretrained_base,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=2048, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(units=1024, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(units=512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(units=197, activation=\"Softmax\"),\n",
    "])\n",
    "\n",
    "# Custom base  0.8051346 val_binary_accuracy\n",
    "\n",
    "# model = keras.Sequential([\n",
    "\n",
    "#     # First Convolutional Block\n",
    "#     # 32 filter layers, Kernel Size of 5 x 5. Relu activation.  Add zeroes all around so the image doesn't change size, Padding='same'.\n",
    "    \n",
    "#     layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same',\n",
    "#                   # give the input dimensions in the first layer\n",
    "#                   # [height, width, color channels(RGB)]\n",
    "#                   input_shape=[256, 256, 3]),\n",
    "#     layers.Dropout(0.4),\n",
    "#     layers.MaxPool2D(),\n",
    "\n",
    "#     # Second Convolutional Block\n",
    "#     layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "#     layers.Dropout(0.4),\n",
    "#     layers.MaxPool2D(),\n",
    "    \n",
    "\n",
    "#     # Third Convolutional Block\n",
    "#     layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "#     layers.Dropout(0.4),\n",
    "#     layers.MaxPool2D(),\n",
    "#     layers.BatchNormalization(),\n",
    "\n",
    "#     #Fourth Convolutional Block\n",
    "#     layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "#     layers.Dropout(0.4),\n",
    "#     layers.MaxPool2D(),\n",
    "    \n",
    "\n",
    "#     #Fifth Convolutional Block\n",
    "#     layers.Conv2D(filters=512, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "#     layers.Dropout(0.4),\n",
    "#     layers.MaxPool2D(),\n",
    "\n",
    "   \n",
    "# #     # Classifier Head.  Fully connected Dense layer with 6 nodes and a relu activation.  Final node for binary decision. \n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(units=2048, activation=\"relu\"),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.4),\n",
    "#     layers.Dense(units=1024, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.4),\n",
    "#     layers.Dense(units=512, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.4),\n",
    "#     layers.Dense(units=197, activation=\"Softmax\"),\n",
    "\n",
    "# ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 20:15:59.249040: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 90 of 100\n",
      "2021-11-16 20:16:00.397612: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10/128 [=>............................] - ETA: 5:25 - loss: 6.0308 - accuracy: 0.0141"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bv/1hmr6s5n4v33fvhx6nwgdmr40000gn/T/ipykernel_91601/2836515478.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m )\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Compile.  Use the Adam optimizer which uses stochastic gradient descent to adjust weights.  Binary_crossentropy since it's either 'car' or 'truck.\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Fit the Model. \n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data = ds_test,\n",
    "    epochs = 50,\n",
    "    callbacks=[early_stopping], \n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.648878</td>\n",
       "      <td>0.064833</td>\n",
       "      <td>4.374334</td>\n",
       "      <td>0.116652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.535688</td>\n",
       "      <td>0.157785</td>\n",
       "      <td>3.088226</td>\n",
       "      <td>0.215769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.784579</td>\n",
       "      <td>0.274681</td>\n",
       "      <td>2.818858</td>\n",
       "      <td>0.269369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.094135</td>\n",
       "      <td>0.422888</td>\n",
       "      <td>2.608553</td>\n",
       "      <td>0.316005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.482090</td>\n",
       "      <td>0.577726</td>\n",
       "      <td>2.316159</td>\n",
       "      <td>0.385773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.018251</td>\n",
       "      <td>0.706532</td>\n",
       "      <td>2.253379</td>\n",
       "      <td>0.411640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.661281</td>\n",
       "      <td>0.816552</td>\n",
       "      <td>2.283962</td>\n",
       "      <td>0.422336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.463584</td>\n",
       "      <td>0.876228</td>\n",
       "      <td>2.277894</td>\n",
       "      <td>0.439249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.317024</td>\n",
       "      <td>0.914661</td>\n",
       "      <td>2.325976</td>\n",
       "      <td>0.441736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.249713</td>\n",
       "      <td>0.934553</td>\n",
       "      <td>2.255388</td>\n",
       "      <td>0.465116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.208704</td>\n",
       "      <td>0.944990</td>\n",
       "      <td>2.346641</td>\n",
       "      <td>0.447332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.172411</td>\n",
       "      <td>0.956410</td>\n",
       "      <td>2.367880</td>\n",
       "      <td>0.462132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.163740</td>\n",
       "      <td>0.956655</td>\n",
       "      <td>2.390242</td>\n",
       "      <td>0.457530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.152354</td>\n",
       "      <td>0.957760</td>\n",
       "      <td>2.563542</td>\n",
       "      <td>0.445218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.127281</td>\n",
       "      <td>0.965742</td>\n",
       "      <td>2.393007</td>\n",
       "      <td>0.459893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.104990</td>\n",
       "      <td>0.974460</td>\n",
       "      <td>2.505142</td>\n",
       "      <td>0.461510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.107856</td>\n",
       "      <td>0.971022</td>\n",
       "      <td>2.570564</td>\n",
       "      <td>0.459396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.119186</td>\n",
       "      <td>0.963531</td>\n",
       "      <td>2.584196</td>\n",
       "      <td>0.468598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.132726</td>\n",
       "      <td>0.962672</td>\n",
       "      <td>2.769879</td>\n",
       "      <td>0.439498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.122971</td>\n",
       "      <td>0.963900</td>\n",
       "      <td>2.937853</td>\n",
       "      <td>0.424698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.155040</td>\n",
       "      <td>0.952235</td>\n",
       "      <td>2.746772</td>\n",
       "      <td>0.447706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   4.648878  0.064833  4.374334      0.116652\n",
       "1   3.535688  0.157785  3.088226      0.215769\n",
       "2   2.784579  0.274681  2.818858      0.269369\n",
       "3   2.094135  0.422888  2.608553      0.316005\n",
       "4   1.482090  0.577726  2.316159      0.385773\n",
       "5   1.018251  0.706532  2.253379      0.411640\n",
       "6   0.661281  0.816552  2.283962      0.422336\n",
       "7   0.463584  0.876228  2.277894      0.439249\n",
       "8   0.317024  0.914661  2.325976      0.441736\n",
       "9   0.249713  0.934553  2.255388      0.465116\n",
       "10  0.208704  0.944990  2.346641      0.447332\n",
       "11  0.172411  0.956410  2.367880      0.462132\n",
       "12  0.163740  0.956655  2.390242      0.457530\n",
       "13  0.152354  0.957760  2.563542      0.445218\n",
       "14  0.127281  0.965742  2.393007      0.459893\n",
       "15  0.104990  0.974460  2.505142      0.461510\n",
       "16  0.107856  0.971022  2.570564      0.459396\n",
       "17  0.119186  0.963531  2.584196      0.468598\n",
       "18  0.132726  0.962672  2.769879      0.439498\n",
       "19  0.122971  0.963900  2.937853      0.424698\n",
       "20  0.155040  0.952235  2.746772      0.447706"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['accuracy', 'val_accuracy']].plot()\n",
    "# history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();\n",
    "# print(history_frame.val_binary_accuracy)\n",
    "history_frame"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e47b1a34c05c1e3b83a62d7885c9d1b5ef8a0522d3be0182d0a008ec409b2b3d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('myenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
