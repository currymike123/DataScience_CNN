{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My First Visual Studio Code, Tensorflow, & Jupyter Notebook Project\n",
    "\n",
    "Code copied from https://www.kaggle.com/ryanholbrook/custom-convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00002.jpg', [100, 19, 576, 203], 103]\n"
     ]
    }
   ],
   "source": [
    "# Load training and validation sets\n",
    "\n",
    "\n",
    "cars_meta = scipy.io.loadmat('./Annos/cars_meta.mat')\n",
    "class_names = cars_meta['class_names']  # shape=(1, 196)\n",
    "class_names = np.transpose(class_names)\n",
    "\n",
    "train_annos = scipy.io.loadmat('./Annos/cars_train_annos.mat')\n",
    "train_annos = train_annos['annotations']\n",
    "train_annos = np.transpose(train_annos)\n",
    "\n",
    "test_annos = scipy.io.loadmat('./Annos/cars_test_annos_withlabels.mat')\n",
    "test_annos = test_annos['annotations']\n",
    "test_annos = np.transpose(test_annos)\n",
    "\n",
    "def format_annotations(data):\n",
    "\n",
    "    annos = []\n",
    "\n",
    "    for annotation in data:\n",
    "        bbox_x1 = annotation[0][0][0][0]\n",
    "        bbox_y1 = annotation[0][1][0][0]\n",
    "        bbox_x2 = annotation[0][2][0][0]\n",
    "        bbox_y2 = annotation[0][3][0][0]\n",
    "        class_id = annotation[0][4][0][0]\n",
    "        fname = annotation[0][5][0]\n",
    "        annos.append([fname,[bbox_x1, bbox_y1, bbox_x2, bbox_y2],class_id])\n",
    "       \n",
    "\n",
    "    return(annos)\n",
    "\n",
    "train_annotations = format_annotations(train_annos)\n",
    "test_annotations = format_annotations(test_annos)\n",
    "\n",
    "print(test_annotations[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reproducability\n",
    "# Setup the random seed so training data is feed in the same each run.\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "# The plotting layout presets.\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "\n",
    "\n",
    "# Create a tensorflow datasta (tf.data.Dataset).  Matches the images with the binary label \"Car\" or \"Truck\".  All the images are 128x128 and if they need to be resized use nearsest neighbor interpolation.    Shuffle the training set.  Do not shuffle the validation set.  It doesn't matter the order of the validation no need to shuffle. \n",
    "ds_train_ = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    './car_truck/train',\n",
    "    labels='inferred',\n",
    "    #Changed from binary to categorical_crossentropy because of the expanded labels.\n",
    "    label_mode='categorical_crossentropy',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_valid_ = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    './car_truck/valid',\n",
    "    labels='inferred',\n",
    "    #Changed from binary to categorical_crossentropy because of the expanded labels.\n",
    "    label_mode='categorical_crossentropy',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Data Pipeline\n",
    "# Process the images into pixel arrays so matrix operations can be preformed on them.  \n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "# Putting it all together.  Take the training dataset which is sized and labeled.  Convert to pixel array.  Cache in memory for faster runtime.  Autotune sets up the CPU so it's fetching the next image in the list while the current image is in the CNN.  \n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Pretrained Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16 pretrained base for baseline.\n",
    "\n",
    "pretrained_base = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=[128,128,3],\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "pretrained_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop early if the accucary is not improving enough.\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=5, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pretrained base model\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     pretrained_base,\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(6, activation='relu'),\n",
    "#     layers.Dense(1, activation='sigmoid'),\n",
    "# ])\n",
    "\n",
    "# Custom base  0.8051346 val_binary_accuracy\n",
    "\n",
    "model = keras.Sequential([\n",
    "\n",
    "    # First Convolutional Block\n",
    "    # 32 filter layers, Kernel Size of 5 x 5. Relu activation.  Add zeroes all around so the image doesn't change size, Padding='same'.\n",
    "    layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same',\n",
    "                  # give the input dimensions in the first layer\n",
    "                  # [height, width, color channels(RGB)]\n",
    "                  input_shape=[128, 128, 3]),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    #Fourth Convolutional Block\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Classifier Head.  Fully connected Dense layer with 6 nodes and a relu activation.  Final node for binary decision. \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=6, activation=\"relu\"),\n",
    "    layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile.  Use the Adam optimizer which uses stochastic gradient descent to adjust weights.  Binary_crossentropy since it's either 'car' or 'truck.\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "# Fit the Model. \n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping], \n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();\n",
    "print(history_frame.val_binary_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e47b1a34c05c1e3b83a62d7885c9d1b5ef8a0522d3be0182d0a008ec409b2b3d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('myenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
